{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab8491fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3.3 조기종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b894d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd0fa534",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52e85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 불러오는 과정에서 원하는 preprocessing 과정\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc65049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 train / test data 를 불러옴\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=r'../chap08/data/archive/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True,\n",
    ")\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    root=r'../chap08/data/archive/test',\n",
    "    transform=val_transform\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "070abec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50(pretrained=True):\n",
    "    # transfer learning을 위한 resnet을 가져옴\n",
    "    model = models.resnet50(progress=True, pretrained=pretrained)\n",
    "    if requires_grad == False:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif requires_grad == True:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    # 마지막 원하는 포멧과 함께 2 class 문제 해결\n",
    "    model.fc = nn.Linear(2048, 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0301b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRScheduler():\n",
    "    def __init__(\n",
    "        self, optimizer, patience=5, min_lr=1e-6, factor=0.5\n",
    "    ):\n",
    "        # 해당하는 optimizer , patinece , learning rate , factor 등을 기입\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.factor = factor\n",
    "        # 스케쥴러를 통해 작성\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "                self.optimizer,\n",
    "                mode='min',\n",
    "                patience=self.patience,\n",
    "                factor=self.factor,\n",
    "                min_lr=self.min_lr,\n",
    "                verbose=True\n",
    "            )\n",
    "    def __call__(self, val_loss):\n",
    "        self.lr_scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9956b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    # 만약에 학습이 더디거나 충분히 학습되면, 그전에 early stopping\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='../chap08/data/checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                # 만약에 patience 횟수만큼 진정이 없으면 stop을 위한용도\n",
    "                self.early_stop = True\n",
    "                \n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3209f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "#해당하는 행동을 이제 schedular에 argument를 넣어서 해결\n",
    "parser.add_argument('--lr-scheduler', dest='lr_scheduler', action='store_true')\n",
    "parser.add_argument('--early-stopping', dest='early_stopping', action='store_true')\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\") #주피터 노트북에서 실행할때 필요합니다\n",
    "args = vars(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d84a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation device: cpu\n",
      "\n",
      "25,557,032 total parameters.\n",
      "25,557,032 training parameters.\n"
     ]
    }
   ],
   "source": [
    "#!pip install ipywidgets 혹은\n",
    "#anaconda prompt에서 conda install -c conda-forge ipywidgets 실행\n",
    "\n",
    "# resnet을 가져오고 그에 해당하는 요소들을 print\n",
    "print(f\"Computation device: {device}\\n\")\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "124584a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 100\n",
    "\n",
    "# learing rate , epoch 설정 후, \n",
    "# loss 와 optimization 함수를 설정.\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2a9cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot_name = 'loss'\n",
    "acc_plot_name = 'accuracy'\n",
    "model_name = 'model'\n",
    "\n",
    "# 이름을 기입하여, 스케쥴러에 넣어줄 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66f2f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#argument가 무엇인지에 따라, name을 달리 설정해줌.\n",
    "if args['lr_scheduler']:\n",
    "    print('INFO: Initializing learning rate scheduler')\n",
    "    lr_scheduler = LRScheduler(optimizer)\n",
    "    loss_plot_name = 'lrs_loss'\n",
    "    acc_plot_name = 'lrs_accuracy'\n",
    "    model_name = 'lrs_model'\n",
    "if args['early_stopping']:\n",
    "    print('INFO: Initializing early stopping')\n",
    "    early_stopping = EarlyStopping()\n",
    "    loss_plot_name = 'es_loss'\n",
    "    acc_plot_name = 'es_accuracy'\n",
    "    model_name = 'es_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73b46db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(model, train_dataloader, train_dataset, optimizer, criterion):\n",
    "    print('Training')\n",
    "    # 학습을 위한 용도 model.train\n",
    "    # 그에 해당하는 loss & correct 리스트화 / counter 및 total\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    prog_bar = tqdm(enumerate(train_dataloader), total=int(len(train_dataset)/train_dataloader.batch_size))\n",
    "    for i, data in prog_bar:\n",
    "        counter += 1\n",
    "        # 분석하는 환경에 맞게 데이터 전환\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        total += target.size(0)\n",
    "        \n",
    "        # optimizer 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #학습\n",
    "        outputs = model(data)\n",
    "        \n",
    "        #loss 구하기 및 backwarding\n",
    "        loss = criterion(outputs, target)\n",
    "        train_running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == target).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_running_loss / counter\n",
    "    train_accuracy = 100. * train_running_correct / total\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9504f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, test_dataloader, val_dataset, criterion):\n",
    "    print('Validating')\n",
    "    # 검증을 위한 용도 model.eval\n",
    "    # 그에 해당하는 loss & correct 리스트화 / counter 및 total\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    prog_bar = tqdm(enumerate(test_dataloader), total=int(len(val_dataset)/test_dataloader.batch_size))\n",
    "    with torch.no_grad():\n",
    "        for i, data in prog_bar:\n",
    "            counter += 1\n",
    "            # 분석하는 환경에 맞게 데이터 전환\n",
    "            data, target = data[0].to(device), data[1].to(device)\n",
    "            total += target.size(0)\n",
    "            \n",
    "            #학습 및 loss 구하기\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            \n",
    "            val_running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_running_correct += (preds == target).sum().item()\n",
    "        \n",
    "        val_loss = val_running_loss / counter\n",
    "        val_accuracy = 100. * val_running_correct / total\n",
    "        return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f79b9c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [07:32, 28.26s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [02:00,  7.51s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2386, Train Acc: 60.64\n",
      "Val Loss: 106.3847, Val Acc: 0.20\n",
      "Epoch 2 of 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [08:14, 30.93s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [02:09,  8.08s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6305, Train Acc: 66.47\n",
      "Val Loss: 1.6918, Val Acc: 54.00\n",
      "Epoch 3 of 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [08:11, 30.74s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [02:18,  8.68s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5101, Train Acc: 76.31\n",
      "Val Loss: 0.6113, Val Acc: 71.60\n",
      "Epoch 4 of 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [07:58, 29.91s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [02:05,  7.85s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4951, Train Acc: 76.10\n",
      "Val Loss: 0.6003, Val Acc: 68.80\n",
      "Epoch 5 of 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [07:06, 26.66s/it]                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/15 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jl/wmntyy4d25q2v0ldmswng8040000gn/T/ipykernel_42426/4176801163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0;31m     val_epoch_loss, val_epoch_accuracy = validate(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n",
      "\u001b[0;32m/var/folders/jl/wmntyy4d25q2v0ldmswng8040000gn/T/ipykernel_42426/2442356645.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, test_dataloader, val_dataset, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m#학습 및 loss 구하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    451\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 453\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    454\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 전체 loss & accuracy를 보여줌.\n",
    "train_loss, train_accuracy = [], []\n",
    "val_loss, val_accuracy = [], []\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    \n",
    "    # 각 epoch 마다, train -> validation을 반복\n",
    "    train_epoch_loss, train_epoch_accuracy = training(\n",
    "        model, train_dataloader, train_dataset, optimizer, criterion\n",
    "    )\n",
    "    val_epoch_loss, val_epoch_accuracy = validate(\n",
    "        model, val_dataloader, val_dataset, criterion\n",
    "    )\n",
    "    \n",
    "    # 그에 해당하는 loss / accuracy도 추가\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "    \n",
    "    # argument가 어떤 것인지에 따라서, 다르게 판단해줌.\n",
    "    if args['lr_scheduler']:\n",
    "        lr_scheduler(val_epoch_loss)\n",
    "    if args['early_stopping']:\n",
    "        early_stopping(val_epoch_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_accuracy:.2f}\")\n",
    "    print(f'Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_accuracy:.2f}')\n",
    "end = time.time()\n",
    "print(f\"Training time: {(end-start)/60:.3f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85120f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위에 분석을 통해 얻은 list화된 loss & accuracy 등을 plotting 함.\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_accuracy, color='green', label='train accuracy')\n",
    "plt.plot(val_accuracy, color='blue', label='validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(f\"../chap08/img/{acc_plot_name}.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.plot(val_loss, color='red', label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(f\"../chap08/img/{loss_plot_name}.png\")\n",
    "plt.show()\n",
    "    \n",
    "print('Saving model...')\n",
    "torch.save(model.state_dict(), f\"../chap08/img/{model_name}.pth\")\n",
    "print('TRAINING COMPLETE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
